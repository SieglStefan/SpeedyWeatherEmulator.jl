using SpeedyWeatherEmulator
using Plots
using ProgressMeter
using Measures



### Prepare emulator evaluation

# Define simulation parameters and load/format simulation data generated by "generate_data.jl"
const TRUNC = 5
const N_DATA = 48
const N_IC = 1000

sim_para_loading = SimPara(trunc=TRUNC, n_data=N_DATA, n_ic=N_IC)
sim_data = load_data(sim_para_loading, type="sim_data")
fd = FormattedData(sim_data)

# Define the parameters for the coarse hyperparameter optimization
L_list = [1,2,3]                        # number of hidden layers
W_list_coarse = [64, 128, 256, 512]     # number of neurons per hidden layer

# Calculate number of spectral coeff.
d = 2*calc_n_coeff(trunc=TRUNC)                                

# Calculate the overall number of parameters of the neural network
n_params(d, W, L) = (d*W + W) + (L-1)*(W*W + W) + (W*d + d)

# Define dict. for better accessing rel. error, training time and number of network parameters
data = Dict{Tuple{Int,Int}, NamedTuple}()                     


# Fill the data dict. for all coarse hyperparameter
@showprogress for L in L_list, W in W_list_coarse

    # Define simulation parameters for specific hyperparameter
    id = "_hyperpara_L$(L)_W$(W)"
    sim_para = SimPara(trunc=TRUNC, n_data=N_DATA, n_ic=N_IC, id_key=id)

    # Load the specific emulator and hyperparameter (generated by "hyperpara_opt_coarse.jl")
    em = load_data(sim_para, type="emulator")
    losses = load_data(sim_para, type="losses")

    # Define container for rel. errors for different forecast lengths
    err_vec = zeros(N_DATA)

    # Compare the emulator for different forecast lengths
    for steps in 1:N_DATA
        err_vec[steps] = compare_emulator(  em,
                                            x_test=fd.data_pairs.x_valid,
                                            y_test=fd.data_pairs.y_valid,
                                            n_it=steps)

    end

    # Initialize the dict.
    data[(L,W)] = ( err = err_vec,
                    training_time = losses.training_time,
                    params = n_params(d, W, L))
end



### Emulator evaluation (plots)


## Plot the correlation of training time and number of neural network parameters 
# Define the neural network parameters and training times as lists
params = [data[(L,W)].params for L in L_list for W in W_list_coarse]
times  = [data[(L,W)].training_time for L in L_list for W in W_list_coarse]

# Define different colors for different L values
colors = [L for L in L_list for W in W_list_coarse]

# Plot the correlation
scatter(params, times;
        group=colors,
        xlabel="Number of parameters",
        ylabel="Training time [s]",
        title="Training time vs. #params (colored by L)")


## Plot the rel. error to the number of neural network parameters
# Define compared forecast lengths and marker symbols
horizons      = [1, 6, 12, 24]
marker_shapes = Dict(1=>:circle, 2=>:square, 3=>:diamond)

# Define empty plot
plots = Plots.Plot[]

# Generate different subplots
for h in horizons
    p = plot(xlabel="#parameters", ylabel="Relative error", title="h = $(h)h")
    for L in L_list 
        xs = [data[(L,W)].params for W in W_list_coarse]
        ys = [data[(L,W)].err[h] for W in W_list_coarse]
        scatter!(p, xs, ys; markershape=marker_shapes[L], label="L = $L", markersize=6)
    end
    push!(plots, p)
end

# Combine subplots to a single plot
plot(plots...;  layout=(2,2), 
                xscale=:log10, 
                plot_title="Relative Forecast Error vs. Model Size for Different Prediction Horizons", 
                size=(1000,800), margin=5mm, plot_margin=5mm)